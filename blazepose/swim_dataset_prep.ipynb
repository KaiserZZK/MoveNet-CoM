{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14dca50",
   "metadata": {},
   "source": [
    "# Preparing training dataset for BlazePose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76516efb",
   "metadata": {},
   "source": [
    "## example format\n",
    "\n",
    "```JSON\n",
    "[\n",
    "    {\n",
    "        \"image\": \"001.png\",\n",
    "        \"points\": [[280, 540], [315, 468], [356, 354], [354, 243], [471, 331], [514, 440], [546, 540]],\n",
    "        \"visibility\": [1, 1, 1, 1, 0, 0, 1]\n",
    "    }\n",
    "    {\n",
    "        \"image\": \"002.png\",\n",
    "        \"points\": [[269, 529], [289, 465], [305, 410], [310, 309], [455, 358], [542, 429], [560, 542]],\n",
    "        \"visibility\": [1, 0, 0, 1, 1, 1, 1]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513bbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from adjustText import adjust_text\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b101dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(os.getcwd()).parent\n",
    "sys.path.append(root)\n",
    "\n",
    "dataset_name = ['mpii']\n",
    "dataset_path = list(map(lambda x: os.path.join(root, 'data', x), dataset_name))\n",
    "\n",
    "# Format of filenames = [[mpii_img_1, mpii_img_2, ... (mpii_img_k)]]\n",
    "filenames_ = list(map(lambda path, name: open(os.path.join(path, '{}_filenames.txt'.format(name))), dataset_path, dataset_name))\n",
    "filenames = list(map(lambda f: f.read().split(), filenames_))\n",
    "_ = list(map(lambda f: f.close(), filenames_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce80715",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = {'swimming, backstroke',\n",
    "              'swimming, breaststroke, recreational',\n",
    "              'swimming, butterfly, general',\n",
    "              'swimming, general',\n",
    "              'swimming, sidestroke, general'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2feb288",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(Path(os.getcwd()), 'swim_dataset', 'images')\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb187d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index to joint name conversion\n",
    "mpii_idx_to_jnt = {0: 'rankl', 1: 'rknee', 2: 'rhip', 5: 'lankl', 4: 'lknee', 3: 'lhip',\n",
    "                   6: 'pelvis', 7: 'thorax', 8: 'upper_neck', 11: 'relb', 10: 'rwri', 9: 'head',\n",
    "                   12: 'rsho', 13: 'lsho', 14: 'lelb', 15: 'lwri'}\n",
    "\n",
    "# This template will then be updated as and when we read ground truth\n",
    "mpii_template = dict([(mpii_idx_to_jnt[i], []) for i in range(16)])\n",
    "\n",
    "# Load the mat file.\n",
    "matlab_mpii = scipy.io.loadmat(os.path.join(dataset_path[0], 'joints.mat'), struct_as_record=False)['RELEASE'][0, 0]\n",
    "num_images = annotation_mpii = matlab_mpii.__dict__['annolist'][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2744418",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = \"{:03d}.jpg\"\n",
    "out_idx = 0\n",
    "test_img_num = 0\n",
    "\n",
    "# Create a Python dictionary or list with your data\n",
    "data = []\n",
    "json_file_path = os.path.join(Path(os.getcwd()), 'swim_dataset', \"all_data.json\") \n",
    "with open(json_file_path, 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3939143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(file_path, image_info, write_name):\n",
    "    '''\n",
    "    :param image_info: (dict)\n",
    "    :param image_name: (string)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    points = []\n",
    "    visibilities = []\n",
    "    for item in ('rhip', 'lhip', 'rsho', 'lsho'):\n",
    "\n",
    "        point = [int(x) for x in image_info['mpii']['img_gt'][0][item][0][:2].flatten()]  # no float16 for JSON\n",
    "        points.append(point)\n",
    "        visibility = int(image_info['mpii']['img_gt'][0][item][0][2])\n",
    "        visibilities.append(visibility)\n",
    "\n",
    "    # Dictionary representing the data to append\n",
    "    data = {\n",
    "        \"image\": write_name,\n",
    "        \"points\": points,\n",
    "        \"visibility\": visibilities,\n",
    "        \"original_img_name\": image_info['mpii']['img_name'][0]\n",
    "    }\n",
    "\n",
    "    # Load the existing JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        existing_data = json.load(file)\n",
    "\n",
    "    # Append the new data to the existing data\n",
    "    existing_data.append(data)\n",
    "\n",
    "    # Write the updated data to the JSON file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(existing_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433b1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 24987/24987 [00:05<00:00, 4173.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Start information extraction loop\n",
    "for img_idx in tqdm(range(num_images)):    # Initialize empty placeholder\n",
    "    img_dict = {'mpii': {'img': [], 'img_name': [], 'img_pred': [], 'img_gt': []}}\n",
    "    \n",
    "        \n",
    "    # Select swimming-related images \n",
    "    activity = matlab_mpii.__dict__['act'][img_idx][0].__dict__['act_name']\n",
    "    if activity.shape[0] == 0 or activity[0] not in activities:\n",
    "        continue \n",
    "    else:\n",
    "        out_idx += 1\n",
    "\n",
    "    img_json_name = output_format.format(out_idx)\n",
    "\n",
    "    annotation_mpii = matlab_mpii.__dict__['annolist'][0, img_idx]\n",
    "    train_test_mpii = matlab_mpii.__dict__['img_train'][0, img_idx].flatten()[0]\n",
    "    person_id = matlab_mpii.__dict__['single_person'][img_idx][0].flatten()\n",
    "\n",
    "    # Load the individual image. Throw an exception if image corresponding to filename not available.\n",
    "    img_name = annotation_mpii.__dict__['image'][0, 0].__dict__['name'][0]\n",
    "    try:\n",
    "        image = plt.imread(os.path.join(dataset_path[0], 'images', img_name))\n",
    "    except FileNotFoundError:\n",
    "        print('Could not load filename: {}'.format(img_name))\n",
    "        continue\n",
    "\n",
    "    # Copy images to swim_dataset/images/ folder in filename format \"001.png\"\n",
    "    source = os.path.join(Path(os.getcwd()).parent, 'data', 'mpii', 'images', img_name)\n",
    "    output = os.path.join(out_dir, img_json_name)\n",
    "    shutil.copy(source, output)\n",
    "\n",
    "    # Avoid modifying the template and create a copy\n",
    "    gt_per_image = copy.deepcopy(mpii_template)\n",
    "\n",
    "    # Flag is set to true if atleast one person exists in the image with joint annotations.\n",
    "    # If Flag == True, then the image and GT is considered for visualization, else skip\n",
    "    annotated_person_flag = False\n",
    "\n",
    "    # Iterate over persons\n",
    "    for person in (person_id - 1):\n",
    "        try:\n",
    "            annopoints_img_mpii = annotation_mpii.__dict__['annorect'][0, person].__dict__['annopoints'][0, 0]\n",
    "            num_joints = annopoints_img_mpii.__dict__['point'][0].shape[0]\n",
    "\n",
    "            # Iterate over present joints\n",
    "            for i in range(num_joints):\n",
    "                x = annopoints_img_mpii.__dict__['point'][0, i].__dict__['x'].flatten()[0]\n",
    "                y = annopoints_img_mpii.__dict__['point'][0, i].__dict__['y'].flatten()[0]\n",
    "                id_ = annopoints_img_mpii.__dict__['point'][0, i].__dict__['id'][0][0]\n",
    "                vis = annopoints_img_mpii.__dict__['point'][0, i].__dict__['is_visible'].flatten()\n",
    "\n",
    "                # No entry corresponding to visible\n",
    "                if vis.size == 0:\n",
    "                    vis = 1\n",
    "                else:\n",
    "                    vis = vis.item()\n",
    "\n",
    "                gt_per_joint = np.array([x, y, vis]).astype(np.float16)\n",
    "                gt_per_image[mpii_idx_to_jnt[id_]].append(gt_per_joint)\n",
    "\n",
    "            annotated_person_flag = True\n",
    "        except KeyError:\n",
    "            # Person 'x' could not have annotated joints, hence move to person 'y'\n",
    "            continue\n",
    "\n",
    "    if not annotated_person_flag:\n",
    "        continue\n",
    "\n",
    "    # Update the template copy with image, name and ground truth\n",
    "    img_dict['mpii']['img'].append(image)\n",
    "    img_dict['mpii']['img_name'].append(img_name)\n",
    "    img_dict['mpii']['img_gt'].append(gt_per_image)\n",
    "\n",
    "    try:\n",
    "        write_json(json_file_path, img_dict, img_json_name)\n",
    "    except IndexError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa6e121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 147\n"
     ]
    }
   ],
   "source": [
    "json_file = os.path.join(Path(os.getcwd()), 'swim_dataset', 'all_data.json')\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Count the items in the JSON data\n",
    "count = len(data)\n",
    "\n",
    "# Print the count\n",
    "print(\"Number of items:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf82646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def visualize_json(json_input):\n",
    "    \n",
    "    # Read the JSON file\n",
    "    with open(json_input, 'r') as file:\n",
    "        image_infos = json.load(file)\n",
    "    \n",
    "    img_dump = os.path.join(os.getcwd(), 'results', 'viz_gt')\n",
    "    os.makedirs(img_dump, exist_ok=True)\n",
    "\n",
    "    for i in tqdm(range(len(image_infos))):\n",
    "        \n",
    "        image_info = image_infos[i]\n",
    "        \n",
    "        img_name = image_info['image']\n",
    "        pts = image_info[\"points\"]\n",
    "        vis = image_info[\"visibility\"]\n",
    "        file_name = os.path.join(Path(os.getcwd()), 'swim_dataset', 'images', img_name)\n",
    "        img = plt.imread(file_name)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        for i in range(4):\n",
    "            x, y = pts[i][0], pts[i][1]\n",
    "            v = vis[i]\n",
    "            if v == 1:\n",
    "                plt.plot(x, y, marker='v', color=\"blue\")\n",
    "        \n",
    "        # Save the plotted image\n",
    "        save_path = os.path.join(img_dump, img_name[:-4] + \".png\")\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "        plt.close()  # Close the current figure to avoid memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c2d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 147/147 [00:55<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "visualize_json(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_MoveNet_test1",
   "language": "python",
   "name": "venv_movenet_test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
