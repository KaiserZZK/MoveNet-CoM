{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d800aae",
   "metadata": {},
   "source": [
    "# Preparing training dataset for BlazePose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e450ecd",
   "metadata": {},
   "source": [
    "## example format\n",
    "\n",
    "```JSON\n",
    "[\n",
    "    {\n",
    "        \"image\": \"001.png\",\n",
    "        \"points\": [[280, 540], [315, 468], [356, 354], [354, 243], [471, 331], [514, 440], [546, 540]],\n",
    "        \"visibility\": [1, 1, 1, 1, 0, 0, 1]\n",
    "    }\n",
    "    {\n",
    "        \"image\": \"002.png\",\n",
    "        \"points\": [[269, 529], [289, 465], [305, 410], [310, 309], [455, 358], [542, 429], [560, 542]],\n",
    "        \"visibility\": [1, 0, 0, 1, 1, 1, 1]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdce2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from adjustText import adjust_text\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547ea570",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(os.getcwd()).parent\n",
    "sys.path.append(root)\n",
    "\n",
    "dataset_name = ['mpii']\n",
    "dataset_path = list(map(lambda x: os.path.join(root, 'data', x), dataset_name))\n",
    "\n",
    "# Format of filenames = [[mpii_img_1, mpii_img_2, ... (mpii_img_k)]]\n",
    "filenames_ = list(map(lambda path, name: open(os.path.join(path, '{}_filenames.txt'.format(name))), dataset_path, dataset_name))\n",
    "filenames = list(map(lambda f: f.read().split(), filenames_))\n",
    "_ = list(map(lambda f: f.close(), filenames_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ad11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = {'swimming, backstroke',\n",
    "              'swimming, breaststroke, recreational',\n",
    "              'swimming, butterfly, general',\n",
    "              'swimming, general',\n",
    "              'swimming, sidestroke, general'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0474d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(Path(os.getcwd()), 'swim_dataset', 'images')\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fbe0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index to joint name conversion\n",
    "mpii_idx_to_jnt = {0: 'rankl', 1: 'rknee', 2: 'rhip', 5: 'lankl', 4: 'lknee', 3: 'lhip',\n",
    "                   6: 'pelvis', 7: 'thorax', 8: 'upper_neck', 11: 'relb', 10: 'rwri', 9: 'head',\n",
    "                   12: 'rsho', 13: 'lsho', 14: 'lelb', 15: 'lwri'}\n",
    "\n",
    "# This template will then be updated as and when we read ground truth\n",
    "mpii_template = dict([(mpii_idx_to_jnt[i], []) for i in range(16)])\n",
    "\n",
    "# Load the mat file.\n",
    "matlab_mpii = scipy.io.loadmat(os.path.join(dataset_path[0], 'joints.mat'), struct_as_record=False)['RELEASE'][0, 0]\n",
    "num_images = annotation_mpii = matlab_mpii.__dict__['annolist'][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d847f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and GT in batches of 10000\n",
    "initial_index = 0\n",
    "batch = 1000\n",
    "\n",
    "output_format = \"{:03d}.png\"\n",
    "out_idx = 0\n",
    "test_img_num = 0\n",
    "\n",
    "# Create a Python dictionary or list with your data\n",
    "data = []\n",
    "json_file_path = os.path.join(Path(os.getcwd()), 'swim_dataset', \"all_data.json\") \n",
    "with open(json_file_path, 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc4d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(file_path, image_info, write_name):\n",
    "    '''\n",
    "    :param image_info: (dict)\n",
    "    :param image_name: (string)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    points = []\n",
    "    visibilities = []\n",
    "    for item in ('rhip', 'lhip', 'rsho', 'lsho'):\n",
    "\n",
    "        point = [int(x) for x in image_info['mpii']['img_gt'][0][item][0][:2].flatten()]  # no float16 for JSON\n",
    "        points.append(point)\n",
    "        visibility = int(image_info['mpii']['img_gt'][0][item][0][2])\n",
    "        visibilities.append(visibility)\n",
    "\n",
    "    # Dictionary representing the data to append\n",
    "    data = {\n",
    "        \"image\": write_name,\n",
    "        \"points\": points,\n",
    "        \"visibility\": visibilities,\n",
    "        \"original_img_name\": image_info['mpii']['img_name'][0]\n",
    "    }\n",
    "\n",
    "    # Load the existing JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        existing_data = json.load(file)\n",
    "\n",
    "    # Append the new data to the existing data\n",
    "    existing_data.append(data)\n",
    "\n",
    "    # Write the updated data to the JSON file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(existing_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0deb76b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 4195.18it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 374524.87it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 307027.60it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 307410.14it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 284147.69it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 349671.03it/s]\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:02<00:00, 385.55it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 362327.57it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 7699.53it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 291777.67it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 4702.87it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 321747.78it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 347354.37it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 342448.07it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 338523.33it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 172925.33it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 354998.22it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 197202.69it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 325847.11it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1380.96it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 2579.67it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1036.91it/s]\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:01<00:00, 775.71it/s]\n",
      "100%|███████████████████████████████████| 1000/1000 [00:00<00:00, 156568.14it/s]\n",
      "100%|█████████████████████████████████████| 987/987 [00:00<00:00, 225958.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Start information extraction loop\n",
    "while initial_index < num_images:\n",
    "    # Initialize empty placeholder\n",
    "    img_dict = {'mpii': {'img': [], 'img_name': [], 'img_pred': [], 'img_gt': []}}\n",
    "    \n",
    "    # Iterate over each image\n",
    "    for img_idx in tqdm(range(initial_index, min(initial_index + batch, num_images))):\n",
    "        \n",
    "        # Select swimming-related images \n",
    "        activity = matlab_mpii.__dict__['act'][img_idx][0].__dict__['act_name']\n",
    "        if activity.shape[0] == 0 or activity[0] not in activities:\n",
    "            continue \n",
    "        else:\n",
    "            out_idx += 1\n",
    "            \n",
    "        img_json_name = output_format.format(out_idx)\n",
    "    \n",
    "        annotation_mpii = matlab_mpii.__dict__['annolist'][0, img_idx]\n",
    "        train_test_mpii = matlab_mpii.__dict__['img_train'][0, img_idx].flatten()[0]\n",
    "        person_id = matlab_mpii.__dict__['single_person'][img_idx][0].flatten()\n",
    "\n",
    "        # Load the individual image. Throw an exception if image corresponding to filename not available.\n",
    "        img_name = annotation_mpii.__dict__['image'][0, 0].__dict__['name'][0]\n",
    "        try:\n",
    "            image = plt.imread(os.path.join(dataset_path[0], 'images', img_name))\n",
    "        except FileNotFoundError:\n",
    "            print('Could not load filename: {}'.format(img_name))\n",
    "            continue\n",
    "        \n",
    "        # Copy images to swim_dataset/images/ folder in filename format \"001.png\"\n",
    "        source = os.path.join(Path(os.getcwd()).parent, 'data', 'mpii', 'images', img_name)\n",
    "        output = os.path.join(out_dir, img_json_name)\n",
    "        shutil.copy(source, output)\n",
    "        \n",
    "        # Avoid modifying the template and create a copy\n",
    "        gt_per_image = copy.deepcopy(mpii_template)\n",
    "\n",
    "        # Flag is set to true if atleast one person exists in the image with joint annotations.\n",
    "        # If Flag == True, then the image and GT is considered for visualization, else skip\n",
    "        annotated_person_flag = False\n",
    "        \n",
    "        # Iterate over persons\n",
    "        for person in (person_id - 1):\n",
    "            try:\n",
    "                annopoints_img_mpii = annotation_mpii.__dict__['annorect'][0, person].__dict__['annopoints'][0, 0]\n",
    "                num_joints = annopoints_img_mpii.__dict__['point'][0].shape[0]\n",
    "\n",
    "                # Iterate over present joints\n",
    "                for i in range(num_joints):\n",
    "                    x = annopoints_img_mpii.__dict__['point'][0, i].__dict__['x'].flatten()[0]\n",
    "                    y = annopoints_img_mpii.__dict__['point'][0, i].__dict__['y'].flatten()[0]\n",
    "                    id_ = annopoints_img_mpii.__dict__['point'][0, i].__dict__['id'][0][0]\n",
    "                    vis = annopoints_img_mpii.__dict__['point'][0, i].__dict__['is_visible'].flatten()\n",
    "\n",
    "                    # No entry corresponding to visible\n",
    "                    if vis.size == 0:\n",
    "                        vis = 1\n",
    "                    else:\n",
    "                        vis = vis.item()\n",
    "\n",
    "                    gt_per_joint = np.array([x, y, vis]).astype(np.float16)\n",
    "                    gt_per_image[mpii_idx_to_jnt[id_]].append(gt_per_joint)\n",
    "\n",
    "                annotated_person_flag = True\n",
    "            except KeyError:\n",
    "                # Person 'x' could not have annotated joints, hence move to person 'y'\n",
    "                continue\n",
    "\n",
    "        if not annotated_person_flag:\n",
    "            continue\n",
    "\n",
    "        # Update the template copy with image, name and ground truth\n",
    "        img_dict['mpii']['img'].append(image)\n",
    "        img_dict['mpii']['img_name'].append(img_name)\n",
    "        img_dict['mpii']['img_gt'].append(gt_per_image)\n",
    "            \n",
    "        if img_dict['mpii']['img']:\n",
    "            write_json(json_file_path, img_dict, img_json_name)\n",
    "    \n",
    "    initial_index += batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df56ad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 151\n"
     ]
    }
   ],
   "source": [
    "json_file = os.path.join(Path(os.getcwd()), 'swim_dataset', 'all_data.json')\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Count the items in the JSON data\n",
    "count = len(data)\n",
    "\n",
    "# Print the count\n",
    "print(\"Number of items:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51180e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def visualize_json(json_input):\n",
    "    \n",
    "    # Read the JSON file\n",
    "    with open(json_input, 'r') as file:\n",
    "        image_infos = json.load(file)\n",
    "    \n",
    "    colour = {'rankl': (0, 0, 1), 'rknee': (0, 0, 1), 'rhip': (0, 0, 1),\n",
    "              'lankl': (1, 0, 0), 'lknee': (1, 0, 0), 'lhip': (1, 0, 0),\n",
    "              'rwri': (1, 1, 0), 'relb': (1, 1, 0), 'rsho': (1, 1, 0),\n",
    "              'lwri': (0, 1, 0), 'lelb': (0, 1, 0), 'lsho': (0, 1, 0),\n",
    "              'head': (0, 1, 1), 'thorax': (0, 1, 1), 'upper_neck': (0, 1, 1)}\n",
    "\n",
    "    os.makedirs(os.path.join(root, 'results', 'viz_gt'), exist_ok=True)\n",
    "    img_dump = os.path.join(root, 'results', 'viz_gt')\n",
    "\n",
    "    for image_info in image_infos:\n",
    "        # Since we're considering only MPII, the outer loop will execute only once.\n",
    "        for dataset_name_ in image_info.keys():\n",
    "            # Iterate over all images\n",
    "            for i in tqdm(range(len(image_info[dataset_name_]['img']))):\n",
    "\n",
    "                fig, ax = plt.subplots(nrows=1, ncols=1, frameon=False)\n",
    "                ax.set_axis_off()\n",
    "\n",
    "                # Load image, gt for the given index\n",
    "                img = image_info[dataset_name_]['img'][i]\n",
    "                img_name = image_info[dataset_name_]['img_name'][i]\n",
    "                img_gt = image_info[dataset_name_]['img_gt'][i]\n",
    "\n",
    "                # Store joint names which will be displayed on the image\n",
    "                text_overlay = []\n",
    "                ax.imshow(img)\n",
    "\n",
    "                # Color-code the joint and joint name onto the image\n",
    "                joint_names = list(colour.keys())\n",
    "                for jnt in joint_names:\n",
    "                    for jnt_gt in img_gt[jnt]:\n",
    "                        if jnt_gt[2]:\n",
    "                            text_overlay.append(ax.text(x=jnt_gt[0], y=jnt_gt[1], s=jnt, color=colour[jnt], fontsize=6))\n",
    "                            ax.add_patch(Circle(jnt_gt[:2], radius=1.5, color=colour[jnt], fill=False))\n",
    "\n",
    "                # Ensure no crowding of joints on the image\n",
    "                adjust_text(text_overlay)\n",
    "\n",
    "                plt.savefig(fname=os.path.join(img_dump, '{}'.format(img_name)),\n",
    "                            facecolor='black', edgecolor='black', bbox_inches='tight', dpi=300)\n",
    "\n",
    "                plt.close()\n",
    "                del fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a744a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify to visualize based on JSON data\n",
    "\n",
    "# def visualize_image(image_info):\n",
    "#     '''\n",
    "#     :param image_info: (dict)\n",
    "#     '''\n",
    "#     colour = {'rankl': (0, 0, 1), 'rknee': (0, 0, 1), 'rhip': (0, 0, 1),\n",
    "#               'lankl': (1, 0, 0), 'lknee': (1, 0, 0), 'lhip': (1, 0, 0),\n",
    "#               'rwri': (1, 1, 0), 'relb': (1, 1, 0), 'rsho': (1, 1, 0),\n",
    "#               'lwri': (0, 1, 0), 'lelb': (0, 1, 0), 'lsho': (0, 1, 0),\n",
    "#               'head': (0, 1, 1), 'thorax': (0, 1, 1), 'upper_neck': (0, 1, 1)}\n",
    "\n",
    "#     os.makedirs(os.path.join(root, 'results', 'viz_gt'), exist_ok=True)\n",
    "#     img_dump = os.path.join(root, 'results', 'viz_gt')\n",
    "\n",
    "#     # Since we're considering only MPII, the outer loop will execute only once.\n",
    "#     for dataset_name_ in image_info.keys():\n",
    "#         # Iterate over all images\n",
    "#         for i in tqdm(range(len(image_info[dataset_name_]['img']))):\n",
    "\n",
    "#             fig, ax = plt.subplots(nrows=1, ncols=1, frameon=False)\n",
    "#             ax.set_axis_off()\n",
    "\n",
    "#             # Load image, gt for the given index\n",
    "#             img = image_info[dataset_name_]['img'][i]\n",
    "#             img_name = image_info[dataset_name_]['img_name'][i]\n",
    "#             img_gt = image_info[dataset_name_]['img_gt'][i]\n",
    "\n",
    "#             # Store joint names which will be displayed on the image\n",
    "#             text_overlay = []\n",
    "#             ax.imshow(img)\n",
    "\n",
    "#             # Color-code the joint and joint name onto the image\n",
    "#             joint_names = list(colour.keys())\n",
    "#             for jnt in joint_names:\n",
    "#                 for jnt_gt in img_gt[jnt]:\n",
    "#                     if jnt_gt[2]:\n",
    "#                         text_overlay.append(ax.text(x=jnt_gt[0], y=jnt_gt[1], s=jnt, color=colour[jnt], fontsize=6))\n",
    "#                         ax.add_patch(Circle(jnt_gt[:2], radius=1.5, color=colour[jnt], fill=False))\n",
    "\n",
    "#             # Ensure no crowding of joints on the image\n",
    "#             adjust_text(text_overlay)\n",
    "\n",
    "#             plt.savefig(fname=os.path.join(img_dump, '{}'.format(img_name)),\n",
    "#                         facecolor='black', edgecolor='black', bbox_inches='tight', dpi=300)\n",
    "\n",
    "#             plt.close()\n",
    "#             del fig, ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_MoveNet_test1",
   "language": "python",
   "name": "venv_movenet_test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
